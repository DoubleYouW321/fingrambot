from aiogram import F, Router
from aiogram.filters import Command
from aiogram.types import Message, CallbackQuery
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from app.generate import ai_generate
import asyncio
import html
import app.ai_keyboard as ai_kb
from aiogram.types import FSInputFile

ai_router = Router()

class Gen(StatesGroup):
    wait = State()

FINANCE_KEYWORDS = [
    'Ñ„Ð¸Ð½Ð°Ð½Ñ', 'Ð´ÐµÐ½ÑŒÐ³', 'Ð±ÑŽÐ´Ð¶ÐµÑ‚', 'Ð¸Ð½Ð²ÐµÑÑ‚', 'ÐºÑ€ÐµÐ´Ð¸Ñ‚', 'Ð²ÐºÐ»Ð°Ð´', 'ÑÐ±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¸', 
    'Ð½Ð°Ð»Ð¾Ð³', 'Ð¸Ð¿Ð¾Ñ‚ÐµÐº', 'ÑÑ‚Ñ€Ð°Ñ…Ð¾Ð²Ð°Ð½', 'Ð°ÐºÑ†Ð¸', 'Ð¾Ð±Ð»Ð¸Ð³Ð°Ñ†', 'Ñ„Ð¾Ð½Ð´', 'ÐºÑ€Ð¸Ð¿Ñ‚Ð¾',
    'Ð±Ð¸Ñ‚ÐºÐ¾Ð¸Ð½', 'ÑÑ„Ð¸Ñ€', 'Ð´ÐµÐ¿Ð¾Ð·Ð¸Ñ‚', 'Ð·Ð°ÐµÐ¼', 'Ð´Ð¾Ð»Ð³', 'Ð´Ð¾Ñ…Ð¾Ð´', 'Ñ€Ð°ÑÑ…Ð¾Ð´', 'ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸',
    'Ð¿ÐµÐ½ÑÐ¸', 'Ð½Ð°ÐºÐ¾Ð¿Ð»ÐµÐ½', 'Ñ‚Ñ€Ð°Ñ‚', 'Ð¿Ð¾ÐºÑƒÐ¿Ðº', 'Ñ†ÐµÐ½Ð°', 'ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚', 'Ñ€ÑƒÐ±Ð»', 'Ð´Ð¾Ð»Ð»Ð°Ñ€',
    'ÐµÐ²Ñ€Ð¾', 'ÐºÑƒÑ€Ñ', 'Ð²Ð°Ð»ÑŽÑ‚', 'Ð±Ð°Ð½Ðº', 'ÐºÐ°Ñ€Ñ‚', 'Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´', 'Ð¿Ð»Ð°Ñ‚ÐµÐ¶', 'Ð´Ð¾Ð»Ð»Ð°Ñ€', 'Ñ†ÐµÐ½'
]

def is_finance_related(text: str) -> bool:
    text_lower = text.lower()
    return any(keyword in text_lower for keyword in FINANCE_KEYWORDS)

@ai_router.message(Command('ai_consultation'))
async def cmd_start_consultation(message: Message):
    await message.answer('ðŸ¤– Ð¤Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ð¹ AI-ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ð½Ñ‚', reply_markup=ai_kb.consult_choose)

@ai_router.callback_query(F.data == 'start_consult')
async def cmd_start_consult(callback: CallbackQuery, state: FSMContext):
    await state.set_state(Gen.wait)
    await callback.answer('')
    text = '''Ð—Ð°Ð´Ð°Ð²Ð°Ð¹Ñ‚Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¿Ð¾ Ñ‚ÐµÐ¼Ð°Ð¼:\n
        â€¢ Ð˜Ð½Ð²ÐµÑÑ‚Ð¸Ñ†Ð¸Ð¸ Ð¸ ÑÐ±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¸Ñ\n
        â€¢ ÐšÑ€ÐµÐ´Ð¸Ñ‚Ñ‹ Ð¸ Ð¸Ð¿Ð¾Ñ‚ÐµÐºÐ°\n
        â€¢ Ð‘ÑŽÐ´Ð¶ÐµÑ‚ Ð¸ ÑƒÑ‡ÐµÑ‚ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²\n
        â€¢ ÐÐ°Ð»Ð¾Ð³Ð¸ Ð¸ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð½Ð¾ÑÑ‚ÑŒ\n
        â€¢ Ð¡Ñ‚Ñ€Ð°Ñ…Ð¾Ð²Ð°Ð½Ð¸Ðµ\n
        â€¢ ÐšÑ€Ð¸Ð¿Ñ‚Ð¾Ð²Ð°Ð»ÑŽÑ‚Ñ‹ Ð¸ Ð°ÐºÑ†Ð¸Ð¸\n\n
    ÐžÑ‚Ð²ÐµÑ‡Ð°ÑŽ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹'''

    try:
        photo = FSInputFile("app/images/start_ai.jpg")
        await callback.message.answer_photo(
            photo=photo,
            caption=text
        )
    except Exception as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ñ„Ð¾Ñ‚Ð¾: {e}")
        await callback.message.answer(text)

@ai_router.message(Gen.wait)
async def generating(message: Message, state: FSMContext):
    if len(message.text) > 4000:
        await message.answer("âŒ Ð—Ð°Ð¿Ñ€Ð¾Ñ ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð´Ð»Ð¸Ð½Ð½Ñ‹Ð¹. Ð¡Ð¾ÐºÑ€Ð°Ñ‚Ð¸Ñ‚Ðµ Ð´Ð¾ 4000 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð².")
        await state.clear()
        return
    
    if not is_finance_related(message.text):
        await message.answer(
            "âŒ Ð¯ Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÑŽ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹.\n\n"
            "Ð—Ð°Ð´Ð°Ð¹Ñ‚Ðµ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾ Ñ‚ÐµÐ¼Ð°Ð¼:\n"
            "â€¢ Ð˜Ð½Ð²ÐµÑÑ‚Ð¸Ñ†Ð¸Ð¸ Ð¸ ÑÐ±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¸Ñ\n"
            "â€¢ ÐšÑ€ÐµÐ´Ð¸Ñ‚Ñ‹ Ð¸ Ð±ÑŽÐ´Ð¶ÐµÑ‚\n" 
            "â€¢ ÐÐ°Ð»Ð¾Ð³Ð¸ Ð¸ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ð¾Ðµ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ"
        )
        await state.clear()
        return
    
    processing_msg = await message.answer("ðŸ’¼ ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÑŽ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ...")
    
    try:
        response = await asyncio.wait_for(
            ai_generate(message.text), 
            timeout=60
        )
        
        await processing_msg.delete()
        
        if not response or response.strip() == "":
            await message.answer("âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿ÐµÑ€ÐµÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾Ñ.")
            return
        
        await send_long_message(message, response)
            
    except asyncio.TimeoutError:
        await processing_msg.delete()
        await message.answer("â° ÐŸÑ€ÐµÐ²Ñ‹ÑˆÐµÐ½Ð¾ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð¶Ð¸Ð´Ð°Ð½Ð¸Ñ. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ.")
    
    except Exception as e:
        await processing_msg.delete()
        error_message = str(e)
        
        if "rate limit" in error_message.lower() or "429" in error_message:
            await message.answer("ðŸš« Ð¡Ð»Ð¸ÑˆÐºÐ¾Ð¼ Ð¼Ð½Ð¾Ð³Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð². ÐŸÐ¾Ð´Ð¾Ð¶Ð´Ð¸Ñ‚Ðµ Ð½ÐµÐ¼Ð½Ð¾Ð³Ð¾.")
        elif "timeout" in error_message.lower():
            await message.answer("â° Ð¡ÐµÑ€Ð²Ð¸Ñ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ.")
        else:
            await message.answer("âŒ ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ°. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÐµÑ‰Ðµ Ñ€Ð°Ð·.")
    
    finally:
        await state.clear()

@ai_router.callback_query(F.data == 'consult_info')
async def cmd_help_ai(callback: CallbackQuery):
    help_text = (
        "ðŸ’° Ð¤Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ð¹ AI-ÐºÐ¾Ð½ÑÑƒÐ»ÑŒÑ‚Ð°Ð½Ñ‚\n\n"
        "Ð¯ Ð¿Ð¾Ð¼Ð¾Ð³Ñƒ Ñ:\n"
        "â€¢ Ð˜Ð½Ð²ÐµÑÑ‚Ð¸Ñ†Ð¸ÑÐ¼Ð¸ Ð¸ ÑÐ±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¸ÑÐ¼Ð¸\n"
        "â€¢ ÐšÑ€ÐµÐ´Ð¸Ñ‚Ð°Ð¼Ð¸ Ð¸ Ð¸Ð¿Ð¾Ñ‚ÐµÐºÐ¾Ð¹\n"
        "â€¢ Ð¡Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸ÐµÐ¼ Ð±ÑŽÐ´Ð¶ÐµÑ‚Ð°\n"
        "â€¢ ÐÐ°Ð»Ð¾Ð³Ð¾Ð²Ñ‹Ð¼Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°Ð¼Ð¸\n"
        "â€¢ Ð¤Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ð¼ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼\n\n"
        "ÐšÐ°Ðº Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ:\n"
        "1. Ð—Ð°Ð´Ð°Ð¹Ñ‚Ðµ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ð¿Ð¾ Ñ„Ð¸Ð½Ð°Ð½ÑÐ°Ð¼\n"
        "2. ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚Ðµ Ð»Ð°ÐºÐ¾Ð½Ð¸Ñ‡Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚\n"
        "3. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ ÑÐ¾Ð²ÐµÑ‚Ñ‹\n\n"
        "ÐžÑ‚Ð²ÐµÑ‡Ð°ÑŽ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ðµ Ñ‚ÐµÐ¼Ñ‹"
    )
    await callback.answer('')
    await callback.message.answer(help_text, reply_markup=ai_kb.back_to_consult)

def split_message(text: str, max_length: int = 4096) -> list:
    if len(text) <= max_length:
        return [text]
    
    chunks = []
    current_chunk = ""
    
    paragraphs = text.split('\n\n')
    
    for paragraph in paragraphs:
        if len(paragraph) > max_length:
            sentences = paragraph.split('. ')
            for sentence in sentences:
                if len(current_chunk) + len(sentence) + 2 <= max_length:
                    current_chunk += sentence + ". "
                else:
                    if current_chunk:
                        chunks.append(current_chunk.strip())
                    current_chunk = sentence + ". "
        else:
            if len(current_chunk) + len(paragraph) + 2 <= max_length:
                current_chunk += paragraph + "\n\n"
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = paragraph + "\n\n"
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks

def clean_text(text: str) -> str:
    if not text:
        return ""
    
    text = text.replace('**', '').replace('__', '').replace('```', '')
    text = html.escape(text)
    
    return text

async def send_long_message(message: Message, text: str, delay: float = 0.5):
    clean_text_content = clean_text(text)
    chunks = split_message(clean_text_content)
    
    if len(chunks) == 1:
        await message.answer(chunks[0])
        return
    
    first_chunk = chunks[0] + f"\n\nðŸ“„ Ð¡Ð¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ 1/{len(chunks)}"
    await message.answer(first_chunk)
    
    for i, chunk in enumerate(chunks[1:], 2):
        chunk_with_counter = f"ðŸ“„ ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ðµ {i}/{len(chunks)}:\n\n{chunk}"
        await asyncio.sleep(delay)
        await message.answer(chunk_with_counter)